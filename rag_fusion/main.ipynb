{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-15T13:44:49.834216Z",
     "start_time": "2025-06-15T13:44:49.794743Z"
    }
   },
   "source": [
    "import langchain\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "import re\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.load import dumps, loads"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:37:22.564274Z",
     "start_time": "2025-06-15T13:37:22.537276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "cohere_api_key = os.getenv(\"COHERE_API_KEY\")"
   ],
   "id": "77a78102f524893d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:37:25.932457Z",
     "start_time": "2025-06-15T13:37:25.925314Z"
    }
   },
   "cell_type": "code",
   "source": "doc_path = '../data/pdf.pdf'",
   "id": "4cef55ff8bdd06e3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:41:37.336869Z",
     "start_time": "2025-06-15T13:41:37.312401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    fused_scores = {}\n",
    "    for docs in results:\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = dumps(doc)\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "    return reranked_results"
   ],
   "id": "82452e084aefba59",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:40:20.563945Z",
     "start_time": "2025-06-15T13:40:20.508960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = ChatPromptTemplate(input_variables=['original_query'],\n",
    "                            messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[],template='You are a helpful assistant that generates multiple search queries based on a single input query.')),\n",
    "                            HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['original_query'], template='Generate multiple search queries related to: {question} \\n OUTPUT (3 queries):'))])"
   ],
   "id": "bf17135b1c33d27a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:37:26.713869Z",
     "start_time": "2025-06-15T13:37:26.703594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "\n",
    "    text = text.lower()\n",
    "    text = text.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.replace('\\n', ' ').strip()\n",
    "    return text"
   ],
   "id": "56c5fd4a2a4b49ff",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loader=PyPDFLoader(doc_path)\n",
    "docs=loader.load()\n",
    "docs"
   ],
   "id": "820b0925a2e86de0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:37:42.839625Z",
     "start_time": "2025-06-15T13:37:42.812491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for doc in docs:\n",
    "    doc.page_content = preprocess_text(doc.page_content)"
   ],
   "id": "a6889f728d97e313",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:37:47.071973Z",
     "start_time": "2025-06-15T13:37:46.892510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=200,chunk_overlap=30)\n",
    "chunks = splitter.split_documents(docs)"
   ],
   "id": "ad901f92bd49e38d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:37:56.219768Z",
     "start_time": "2025-06-15T13:37:52.820771Z"
    }
   },
   "cell_type": "code",
   "source": "embeddings = OpenAIEmbeddings()",
   "id": "61f68d9965cb1186",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:38:22.020497Z",
     "start_time": "2025-06-15T13:38:08.263254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vectorstore=Chroma.from_documents(chunks,embeddings)\n",
    "vectorstore_retreiver = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "vectorstore_retreiver"
   ],
   "id": "a38aa0af22a880e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000015CF684C5B0>, search_kwargs={'k': 5})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:38:25.042872Z",
     "start_time": "2025-06-15T13:38:24.992124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "keyword_retriever = BM25Retriever.from_documents(chunks)\n",
    "keyword_retriever.k = 3\n",
    "keyword_retriever"
   ],
   "id": "4e1aa3237de6eb66",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x0000015C917FDA60>, k=3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:38:27.416718Z",
     "start_time": "2025-06-15T13:38:27.409272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ensemble_retriever = EnsembleRetriever(retrievers=[vectorstore_retreiver,keyword_retriever],weights=[0.3, 0.7])\n",
    "ensemble_retriever"
   ],
   "id": "8489b17f0661f6f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000015CF684C5B0>, search_kwargs={'k': 5}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x0000015C917FDA60>, k=3)], weights=[0.3, 0.7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:42:04.340420Z",
     "start_time": "2025-06-15T13:42:04.038389Z"
    }
   },
   "cell_type": "code",
   "source": "llm = ChatOpenAI()",
   "id": "5614ed3b3f9432f5",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "generate_queries = (\n",
    "    prompt | llm | StrOutputParser() | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "generate_queries"
   ],
   "id": "9ff77f893bdaa9ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:44:54.121645Z",
     "start_time": "2025-06-15T13:44:53.890708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ragfusion_chain = generate_queries | ensemble_retriever.map() | reciprocal_rank_fusion\n",
    "langchain.debug = True\n",
    "ragfusion_chain.input_schema.schema()"
   ],
   "id": "e73432d8349d2c80",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_7436\\249600610.py:3: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  ragfusion_chain.input_schema.schema()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'properties': {'question': {'title': 'Question', 'type': 'string'}},\n",
       " 'required': ['question'],\n",
       " 'title': 'PromptInput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:46:22.650902Z",
     "start_time": "2025-06-15T13:46:22.234189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "full_rag_fusion_chain = (\n",
    "    {\n",
    "        \"context\": ragfusion_chain,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "full_rag_fusion_chain.input_schema.schema()"
   ],
   "id": "a1d91437412fbbaa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_7436\\690582261.py:18: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  full_rag_fusion_chain.input_schema.schema()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'properties': {'question': {'title': 'Question', 'type': 'string'},\n",
       "  'root': {'title': 'Root'}},\n",
       " 'required': ['question', 'root'],\n",
       " 'title': 'RunnableParallel<context,question>Input',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:47:28.018797Z",
     "start_time": "2025-06-15T13:47:24.447468Z"
    }
   },
   "cell_type": "code",
   "source": "response1 = full_rag_fusion_chain.invoke(\"What is Dataset Contamination?\")",
   "id": "2d83fe4055068819",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"What is Dataset Contamination?\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"What is Dataset Contamination?\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"What is Dataset Contamination?\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"What is Dataset Contamination?\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are a helpful assistant that generates multiple search queries based on a single input query.\\nHuman: Generate multiple search queries related to: What is Dataset Contamination? \\n OUTPUT (3 queries):\"\n",
      "  ]\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnablePassthrough] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"What is Dataset Contamination?\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnablePassthrough] [2ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"What is Dataset Contamination?\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > llm:ChatOpenAI] [1.49s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"1. How to detect dataset contamination?\\n2. What are the common sources of dataset contamination?\\n3. Best practices for preventing dataset contamination in research studies.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"1. How to detect dataset contamination?\\n2. What are the common sources of dataset contamination?\\n3. Best practices for preventing dataset contamination in research studies.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 31,\n",
      "                \"prompt_tokens\": 47,\n",
      "                \"total_tokens\": 78,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"id\": \"chatcmpl-BihzivyN1tEEdrDD5zEEFuC4EchW0\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--783cfbf8-3910-4d4f-9e57-3ba8761cd7a0-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 47,\n",
      "              \"output_tokens\": 31,\n",
      "              \"total_tokens\": 78,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 31,\n",
      "      \"prompt_tokens\": 47,\n",
      "      \"total_tokens\": 78,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"id\": \"chatcmpl-BihzivyN1tEEdrDD5zEEFuC4EchW0\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"1. How to detect dataset contamination?\\n2. What are the common sources of dataset contamination?\\n3. Best practices for preventing dataset contamination in research studies.\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"1. How to detect dataset contamination?\\n2. What are the common sources of dataset contamination?\\n3. Best practices for preventing dataset contamination in research studies.\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": [\n",
      "    \"1. How to detect dataset contamination?\",\n",
      "    \"2. What are the common sources of dataset contamination?\",\n",
      "    \"3. Best practices for preventing dataset contamination in research studies.\"\n",
      "  ]\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:RunnableEach<EnsembleRetriever>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": [\n",
      "    \"1. How to detect dataset contamination?\",\n",
      "    \"2. What are the common sources of dataset contamination?\",\n",
      "    \"3. Best practices for preventing dataset contamination in research studies.\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:RunnableEach<EnsembleRetriever>] [886ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:reciprocal_rank_fusion] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:reciprocal_rank_fusion] [9ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence] [2.49s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question>] [2.50s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [3ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the question based only on the following context:\\n[(Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'total_pages': 77, 'page': 74, 'page_label': '75'}, page_content='libraries (e.g. gao et al. (2021)). this approach, however, was unable to detect precisely what proportion of a given sample is contaminated, and didnt take into account how evaluation datasets are'), 0.016666666666666666), (Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'total_pages': 77, 'page': 21, 'page_label': '22'}, page_content='and common sense. 2. toxicity,definedasthetendencyofalanguagemodeltogeneratetoxic,rude,adversarial,orimplicitly hateful content. we choosetoxigen(hartvigsen et al., 2022) to measure the amount of'), 0.016666666666666666), (Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'total_pages': 77, 'page': 12, 'page_label': '13'}, page_content='the final performance ofllama 2-chat. while best practices for comprehensively evaluating a generative model is an open research question, the ranking task of the reward has no ambiguity. therefore,'), 0.016666666666666666), (Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'total_pages': 77, 'page': 6, 'page_label': '7'}, page_content='(hendrycks et al., 2021) benchmarks attop 1. https://sustainability.fb.com/2021-sustainability-report/ https://www.mosaicml.com/blog/mpt-7b 7'), 0.01639344262295082), (Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'total_pages': 77, 'page': 21, 'page_label': '22'}, page_content='et al., 2021) to measure how well our llms can generate reliable outputs that agree with factuality and common sense. 2.'), 0.01639344262295082), (Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'total_pages': 77, 'page': 75, 'page_label': '76'}, page_content='40, 50}. sinceinthelimitof l everysamplefallsintoboththe\\\"clean\\\"and\\\"notdirty\\\"(thereisnocontamination), we report the largestl for each dataset that appeared to benefit from contamination to strike a'), 0.01639344262295082), (Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'total_pages': 77, 'page': 75, 'page_label': '76'}, page_content='with only a small delta (-0.9) between the \\\"clean\\\" subset performance and the sampling mean. no other dataset (for any choice ofl) appears to have benefitted from dataset contamination, and we omit'), 0.016129032258064516), (Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'total_pages': 77, 'page': 19, 'page_label': '20'}, page_content='of the most common english pronouns in table 9a. we observe thathe pronouns are generally overrepresented in documents compared toshe pronouns, echoing similar frequency differences observed in'), 0.016129032258064516), (Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'total_pages': 77, 'page': 22, 'page_label': '23'}, page_content='in the bold dataset (race, religion, and gender). as llms are integrated and deployed, we look forward to continuing research that will amplify their potential for positive impact on these important'), 0.016129032258064516), (Document(metadata={'author': '', 'page_label': '2', 'subject': '', 'producer': 'pdfTeX-1.40.25', 'creationdate': '2023-07-20T00:30:36+00:00', 'creator': 'LaTeX with hyperref', 'source': '../data/pdf.pdf', 'trapped': '/False', 'keywords': '', 'total_pages': 77, 'title': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'page': 1}, page_content='. . . . . . . 72 a.6 dataset contamination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75 a.7 model card . . . . . . . . . . . . . . . . . . . . . . . . . . . .'), 0.015873015873015872), (Document(metadata={'author': '', 'page': 1, 'subject': '', 'creator': 'LaTeX with hyperref', 'keywords': '', 'total_pages': 77, 'creationdate': '2023-07-20T00:30:36+00:00', 'page_label': '2', 'source': '../data/pdf.pdf', 'trapped': '/False', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': '', 'moddate': '2023-07-20T00:30:36+00:00'}, page_content='. . . . . . . 72 a.6 dataset contamination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75 a.7 model card . . . . . . . . . . . . . . . . . . . . . . . . . . . .'), 0.015873015873015872), (Document(metadata={'source': '../data/pdf.pdf', 'page': 1, 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'total_pages': 77, 'moddate': '2023-07-20T00:30:36+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'producer': 'pdfTeX-1.40.25', 'creationdate': '2023-07-20T00:30:36+00:00', 'trapped': '/False', 'author': '', 'page_label': '2', 'title': '', 'subject': ''}, page_content='. . . . . . . 72 a.6 dataset contamination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75 a.7 model card . . . . . . . . . . . . . . . . . . . . . . . . . . . .'), 0.015873015873015872), (Document(metadata={'subject': '', 'moddate': '2023-07-20T00:30:36+00:00', 'title': '', 'author': '', 'keywords': '', 'total_pages': 77, 'creationdate': '2023-07-20T00:30:36+00:00', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'trapped': '/False', 'page': 75, 'page_label': '76', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '../data/pdf.pdf'}, page_content='other evaluation datasets had sufficient evidence to be considered affected by contamination. avg. contam. % denotes the average per-sample contamination percentage for the given subset type. models'), 0.015625), (Document(metadata={'subject': '', 'creationdate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'producer': 'pdfTeX-1.40.25', 'page': 75, 'creator': 'LaTeX with hyperref', 'author': '', 'source': '../data/pdf.pdf', 'total_pages': 77, 'moddate': '2023-07-20T00:30:36+00:00', 'page_label': '76', 'keywords': '', 'trapped': '/False', 'title': ''}, page_content='contamination, and we omit results from these datasets for conciseness. 76'), 0.015625), (Document(metadata={'page': 74, 'page_label': '75', 'source': '../data/pdf.pdf', 'trapped': '/False', 'author': '', 'creator': 'LaTeX with hyperref', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'producer': 'pdfTeX-1.40.25', 'creationdate': '2023-07-20T00:30:36+00:00', 'title': '', 'total_pages': 77, 'moddate': '2023-07-20T00:30:36+00:00', 'keywords': ''}, page_content='seen during training, and may provide an undue boost in evaluation performance. earlierwork(brownetal.(2020),weietal.(2022a),duetal.(2022)inmeasuringsuchdatasetcontamination considered an example'), 0.015625), (Document(metadata={'title': '', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'moddate': '2023-07-20T00:30:36+00:00', 'trapped': '/False', 'creator': 'LaTeX with hyperref', 'keywords': '', 'author': '', 'page_label': '75', 'subject': '', 'source': '../data/pdf.pdf', 'producer': 'pdfTeX-1.40.25', 'total_pages': 77, 'page': 74, 'creationdate': '2023-07-20T00:30:36+00:00'}, page_content='seen during training, and may provide an undue boost in evaluation performance. earlierwork(brownetal.(2020),weietal.(2022a),duetal.(2022)inmeasuringsuchdatasetcontamination considered an example'), 0.015384615384615385), (Document(metadata={'source': '../data/pdf.pdf', 'creator': 'LaTeX with hyperref', 'author': '', 'subject': '', 'page': 74, 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'total_pages': 77, 'title': '', 'creationdate': '2023-07-20T00:30:36+00:00', 'trapped': '/False', 'producer': 'pdfTeX-1.40.25', 'keywords': '', 'page_label': '75'}, page_content='the training. a.6 dataset contamination with the increasing scale of publicly available training data, it has become inevitable that some portion of evaluation data is seen during training, and may'), 0.015384615384615385), (Document(metadata={'moddate': '2023-07-20T00:30:36+00:00', 'page_label': '75', 'trapped': '/False', 'subject': '', 'author': '', 'creationdate': '2023-07-20T00:30:36+00:00', 'keywords': '', 'source': '../data/pdf.pdf', 'total_pages': 77, 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': '', 'page': 74}, page_content='the training data. this was a deliberately conservative approach in order to produce a clean subset of the data with high precision, and is used in open-sourced evaluation libraries (e.g. gao et al.'), 0.015384615384615385), (Document(metadata={'keywords': '', 'page': 74, 'trapped': '/False', 'author': '', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '../data/pdf.pdf', 'creationdate': '2023-07-20T00:30:36+00:00', 'title': '', 'subject': '', 'moddate': '2023-07-20T00:30:36+00:00', 'page_label': '75', 'creator': 'LaTeX with hyperref', 'total_pages': 77, 'producer': 'pdfTeX-1.40.25'}, page_content='the training. a.6 dataset contamination with the increasing scale of publicly available training data, it has become inevitable that some portion of evaluation data is seen during training, and may'), 0.015151515151515152), (Document(metadata={'page_label': '75', 'moddate': '2023-07-20T00:30:36+00:00', 'trapped': '/False', 'total_pages': 77, 'title': '', 'producer': 'pdfTeX-1.40.25', 'source': '../data/pdf.pdf', 'creator': 'LaTeX with hyperref', 'page': 74, 'keywords': '', 'creationdate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'author': '', 'subject': ''}, page_content='seen during training, and may provide an undue boost in evaluation performance. earlierwork(brownetal.(2020),weietal.(2022a),duetal.(2022)inmeasuringsuchdatasetcontamination considered an example'), 0.015151515151515152), (Document(metadata={'producer': 'pdfTeX-1.40.25', 'total_pages': 77, 'keywords': '', 'page': 75, 'trapped': '/False', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'creator': 'LaTeX with hyperref', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'page_label': '76', 'moddate': '2023-07-20T00:30:36+00:00', 'source': '../data/pdf.pdf'}, page_content='contamination, and we omit results from these datasets for conciseness. 76'), 0.015151515151515152), (Document(metadata={'page_label': '75', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'page': 74, 'source': '../data/pdf.pdf', 'trapped': '/False', 'creationdate': '2023-07-20T00:30:36+00:00', 'keywords': '', 'subject': '', 'producer': 'pdfTeX-1.40.25', 'total_pages': 77, 'moddate': '2023-07-20T00:30:36+00:00', 'creator': 'LaTeX with hyperref', 'author': '', 'title': ''}, page_content='than 10 tokens in both the evaluation sample and the training set, and define the contamination percentage of a sample to be the percentage of tokens contaminated.'), 0.014925373134328358), (Document(metadata={'keywords': '', 'author': '', 'page_label': '76', 'trapped': '/False', 'source': '../data/pdf.pdf', 'moddate': '2023-07-20T00:30:36+00:00', 'creationdate': '2023-07-20T00:30:36+00:00', 'total_pages': 77, 'page': 75, 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'title': ''}, page_content='other evaluation datasets had sufficient evidence to be considered affected by contamination. avg. contam. % denotes the average per-sample contamination percentage for the given subset type. models'), 0.014925373134328358), (Document(metadata={'page': 75, 'moddate': '2023-07-20T00:30:36+00:00', 'creationdate': '2023-07-20T00:30:36+00:00', 'title': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'total_pages': 77, 'creator': 'LaTeX with hyperref', 'author': '', 'keywords': '', 'producer': 'pdfTeX-1.40.25', 'page_label': '76', 'subject': ''}, page_content='other evaluation datasets had sufficient evidence to be considered affected by contamination. avg. contam. % denotes the average per-sample contamination percentage for the given subset type. models'), 0.014925373134328358)]\\n\\nQuestion: What is Dataset Contamination?\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:RunnableSequence > llm:ChatOpenAI] [1.04s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Dataset contamination refers to the presence of evaluation data in the training set, which can lead to an undue boost in evaluation performance. It has become inevitable due to the increasing scale of publicly available training data.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Dataset contamination refers to the presence of evaluation data in the training set, which can lead to an undue boost in evaluation performance. It has become inevitable due to the increasing scale of publicly available training data.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 40,\n",
      "                \"prompt_tokens\": 5462,\n",
      "                \"total_tokens\": 5502,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"id\": \"chatcmpl-BihzkARhSHWwynqgddun98mWhc5If\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--0ff3cbf8-7bd5-49b5-8c60-04d38e2840d7-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 5462,\n",
      "              \"output_tokens\": 40,\n",
      "              \"total_tokens\": 5502,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 40,\n",
      "      \"prompt_tokens\": 5462,\n",
      "      \"total_tokens\": 5502,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"id\": \"chatcmpl-BihzkARhSHWwynqgddun98mWhc5If\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"Dataset contamination refers to the presence of evaluation data in the training set, which can lead to an undue boost in evaluation performance. It has become inevitable due to the increasing scale of publicly available training data.\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence] [3.55s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"Dataset contamination refers to the presence of evaluation data in the training set, which can lead to an undue boost in evaluation performance. It has become inevitable due to the increasing scale of publicly available training data.\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T14:07:38.097945Z",
     "start_time": "2025-06-15T14:07:37.867249Z"
    }
   },
   "cell_type": "code",
   "source": "response1",
   "id": "a76bb18269f9d194",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset contamination refers to the presence of evaluation data in the training set, which can lead to an undue boost in evaluation performance. It has become inevitable due to the increasing scale of publicly available training data.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "589afea8caeb59e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
