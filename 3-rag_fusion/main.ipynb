{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-15T13:44:49.834216Z",
     "start_time": "2025-06-15T13:44:49.794743Z"
    }
   },
   "source": [
    "import langchain\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "import re\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.load import dumps, loads"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:37:22.564274Z",
     "start_time": "2025-06-15T13:37:22.537276Z"
    }
   },
   "cell_type": "code",
   "source": "load_dotenv()",
   "id": "77a78102f524893d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:37:25.932457Z",
     "start_time": "2025-06-15T13:37:25.925314Z"
    }
   },
   "cell_type": "code",
   "source": "doc_path = '../data/pdf.pdf'",
   "id": "4cef55ff8bdd06e3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:41:37.336869Z",
     "start_time": "2025-06-15T13:41:37.312401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    fused_scores = {}\n",
    "    for docs in results:\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = dumps(doc)\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "    return reranked_results"
   ],
   "id": "82452e084aefba59",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:40:20.563945Z",
     "start_time": "2025-06-15T13:40:20.508960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = ChatPromptTemplate(input_variables=['original_query'],\n",
    "                            messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[],template='You are a helpful assistant that generates multiple search queries based on a single input query.')),\n",
    "                            HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['original_query'], template='Generate multiple search queries related to: {question} \\n OUTPUT (3 queries):'))])"
   ],
   "id": "bf17135b1c33d27a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:37:26.713869Z",
     "start_time": "2025-06-15T13:37:26.703594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "\n",
    "    text = text.lower()\n",
    "    text = text.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.replace('\\n', ' ').strip()\n",
    "    return text"
   ],
   "id": "56c5fd4a2a4b49ff",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loader=PyPDFLoader(doc_path)\n",
    "docs=loader.load()\n",
    "docs"
   ],
   "id": "820b0925a2e86de0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:37:42.839625Z",
     "start_time": "2025-06-15T13:37:42.812491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for doc in docs:\n",
    "    doc.page_content = preprocess_text(doc.page_content)"
   ],
   "id": "a6889f728d97e313",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:37:47.071973Z",
     "start_time": "2025-06-15T13:37:46.892510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=200,chunk_overlap=30)\n",
    "chunks = splitter.split_documents(docs)"
   ],
   "id": "ad901f92bd49e38d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:37:56.219768Z",
     "start_time": "2025-06-15T13:37:52.820771Z"
    }
   },
   "cell_type": "code",
   "source": "embeddings = OpenAIEmbeddings()",
   "id": "61f68d9965cb1186",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:38:22.020497Z",
     "start_time": "2025-06-15T13:38:08.263254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vectorstore=Chroma.from_documents(chunks,embeddings)\n",
    "vectorstore_retreiver = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "vectorstore_retreiver"
   ],
   "id": "a38aa0af22a880e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000015CF684C5B0>, search_kwargs={'k': 5})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:38:25.042872Z",
     "start_time": "2025-06-15T13:38:24.992124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "keyword_retriever = BM25Retriever.from_documents(chunks)\n",
    "keyword_retriever.k = 3\n",
    "keyword_retriever"
   ],
   "id": "4e1aa3237de6eb66",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x0000015C917FDA60>, k=3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:38:27.416718Z",
     "start_time": "2025-06-15T13:38:27.409272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ensemble_retriever = EnsembleRetriever(retrievers=[vectorstore_retreiver,keyword_retriever],weights=[0.3, 0.7])\n",
    "ensemble_retriever"
   ],
   "id": "8489b17f0661f6f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000015CF684C5B0>, search_kwargs={'k': 5}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x0000015C917FDA60>, k=3)], weights=[0.3, 0.7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:42:04.340420Z",
     "start_time": "2025-06-15T13:42:04.038389Z"
    }
   },
   "cell_type": "code",
   "source": "llm = ChatOpenAI()",
   "id": "5614ed3b3f9432f5",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "generate_queries = (\n",
    "    prompt | llm | StrOutputParser() | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "generate_queries"
   ],
   "id": "9ff77f893bdaa9ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:44:54.121645Z",
     "start_time": "2025-06-15T13:44:53.890708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ragfusion_chain = generate_queries | ensemble_retriever.map() | reciprocal_rank_fusion\n",
    "langchain.debug = True\n",
    "ragfusion_chain.input_schema.schema()"
   ],
   "id": "e73432d8349d2c80",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_7436\\249600610.py:3: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  ragfusion_chain.input_schema.schema()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'properties': {'question': {'title': 'Question', 'type': 'string'}},\n",
       " 'required': ['question'],\n",
       " 'title': 'PromptInput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:46:22.650902Z",
     "start_time": "2025-06-15T13:46:22.234189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "full_rag_fusion_chain = (\n",
    "    {\n",
    "        \"context\": ragfusion_chain,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "full_rag_fusion_chain.input_schema.schema()"
   ],
   "id": "a1d91437412fbbaa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_7436\\690582261.py:18: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  full_rag_fusion_chain.input_schema.schema()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'properties': {'question': {'title': 'Question', 'type': 'string'},\n",
       "  'root': {'title': 'Root'}},\n",
       " 'required': ['question', 'root'],\n",
       " 'title': 'RunnableParallel<context,question>Input',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T14:13:08.259601Z",
     "start_time": "2025-06-15T14:13:05.064807Z"
    }
   },
   "cell_type": "code",
   "source": "response1 = full_rag_fusion_chain.invoke(\"How to prevent data contamination?\")",
   "id": "2d83fe4055068819",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"How to prevent data contamination?\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"How to prevent data contamination?\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"How to prevent data contamination?\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"How to prevent data contamination?\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > prompt:ChatPromptTemplate] [2ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are a helpful assistant that generates multiple search queries based on a single input query.\\nHuman: Generate multiple search queries related to: How to prevent data contamination? \\n OUTPUT (3 queries):\"\n",
      "  ]\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnablePassthrough] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"How to prevent data contamination?\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnablePassthrough] [3ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"How to prevent data contamination?\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > llm:ChatOpenAI] [1.29s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"1. Strategies to avoid data contamination in research\\n2. Best practices for preventing data pollution\\n3. Methods to safeguard against data contamination issues\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"1. Strategies to avoid data contamination in research\\n2. Best practices for preventing data pollution\\n3. Methods to safeguard against data contamination issues\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 28,\n",
      "                \"prompt_tokens\": 47,\n",
      "                \"total_tokens\": 75,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"id\": \"chatcmpl-BiiOZUpDW9oo5W3ZuG9XQ7NzjmhZX\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--38d4ccd1-6d05-41d1-9212-89d6a7e712c6-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 47,\n",
      "              \"output_tokens\": 28,\n",
      "              \"total_tokens\": 75,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 28,\n",
      "      \"prompt_tokens\": 47,\n",
      "      \"total_tokens\": 75,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"id\": \"chatcmpl-BiiOZUpDW9oo5W3ZuG9XQ7NzjmhZX\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"1. Strategies to avoid data contamination in research\\n2. Best practices for preventing data pollution\\n3. Methods to safeguard against data contamination issues\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"1. Strategies to avoid data contamination in research\\n2. Best practices for preventing data pollution\\n3. Methods to safeguard against data contamination issues\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": [\n",
      "    \"1. Strategies to avoid data contamination in research\",\n",
      "    \"2. Best practices for preventing data pollution\",\n",
      "    \"3. Methods to safeguard against data contamination issues\"\n",
      "  ]\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:RunnableEach<EnsembleRetriever>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": [\n",
      "    \"1. Strategies to avoid data contamination in research\",\n",
      "    \"2. Best practices for preventing data pollution\",\n",
      "    \"3. Methods to safeguard against data contamination issues\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:RunnableEach<EnsembleRetriever>] [510ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:reciprocal_rank_fusion] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:reciprocal_rank_fusion] [5ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence] [1.81s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > chain:RunnableParallel<context,question>] [1.82s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [2ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the question based only on the following context:\\n[(Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'total_pages': 77, 'page': 73, 'page_label': '74'}, page_content='when interacting with our models. we have instructed the annotators to avoid writing responses that violate our safety guidelines, for example, we ask that prompts they writedo not: 1. promote or'), 0.016666666666666666), (Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'total_pages': 77, 'page': 22, 'page_label': '23'}, page_content='even before rlhf, and thus lays the foundation for high-quality human preference data annotation. 2. safety rlhf: subsequently, we integrate safety in the general rlhf pipeline described in sec- tion'), 0.016666666666666666), (Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'total_pages': 77, 'page': 9, 'page_label': '10'}, page_content='reward for the latest model. in table 6, we report the statistics of reward modeling data that we collected over time, and present them against multiple open-source preference datasets including'), 0.016666666666666666), (Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'total_pages': 77, 'page': 3, 'page_label': '4'}, page_content='general public for research and commercial use: 1. llama 2, an updated version ofllama 1, trained on a new mix of publicly available data. we also increased the size of the pretraining corpus by 40%,'), 0.01639344262295082), (Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'total_pages': 77, 'page': 39, 'page_label': '40'}, page_content='sebastian gehrmann, elizabeth clark, and thibault sellam. repairing the cracked foundation: a survey of obstacles in evaluation practices for generated text.journal of artificial intelligence'), 0.01639344262295082), (Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'total_pages': 77, 'page': 74, 'page_label': '75'}, page_content='the training. a.6 dataset contamination with the increasing scale of publicly available training data, it has become inevitable that some portion of evaluation data is seen during training, and may'), 0.01639344262295082), (Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'total_pages': 77, 'page': 35, 'page_label': '36'}, page_content='like job displacement due to accelerated ai research and an over-reliance on llms leading to training data degradation are also pertinent considerations (acemoglu and restrepo, 2018; autor and'), 0.016129032258064516), (Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'total_pages': 77, 'page': 12, 'page_label': '13'}, page_content='the final performance ofllama 2-chat. while best practices for comprehensively evaluating a generative model is an open research question, the ranking task of the reward has no ambiguity. therefore,'), 0.016129032258064516), (Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'total_pages': 77, 'page': 7, 'page_label': '8'}, page_content='gpt-4 and palm-2-l. we also analysed the potential data contamination and share the details in section a.6. benchmark (shots) gpt-3.5 gpt-4 palm palm-2-l llama 2 mmlu (5-shot) 70.0 86.4 69.3 78.3'), 0.016129032258064516), (Document(metadata={'producer': 'pdfTeX-1.40.25', 'source': '../data/pdf.pdf', 'author': '', 'moddate': '2023-07-20T00:30:36+00:00', 'subject': '', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'total_pages': 77, 'page_label': '76', 'page': 75, 'creationdate': '2023-07-20T00:30:36+00:00', 'trapped': '/False', 'title': '', 'creator': 'LaTeX with hyperref', 'keywords': ''}, page_content='contamination, and we omit results from these datasets for conciseness. 76'), 0.015873015873015872), (Document(metadata={'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'author': '', 'producer': 'pdfTeX-1.40.25', 'total_pages': 77, 'creator': 'LaTeX with hyperref', 'title': '', 'page_label': '2', 'page': 1, 'subject': '', 'trapped': '/False', 'creationdate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '../data/pdf.pdf'}, page_content='. . . . . . . 72 a.6 dataset contamination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75 a.7 model card . . . . . . . . . . . . . . . . . . . . . . . . . . . .'), 0.015873015873015872), (Document(metadata={'creator': 'LaTeX with hyperref', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': '', 'creationdate': '2023-07-20T00:30:36+00:00', 'subject': '', 'moddate': '2023-07-20T00:30:36+00:00', 'total_pages': 77, 'page': 1, 'author': '', 'keywords': '', 'source': '../data/pdf.pdf', 'page_label': '2', 'producer': 'pdfTeX-1.40.25', 'trapped': '/False'}, page_content='. . . . . . . 72 a.6 dataset contamination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75 a.7 model card . . . . . . . . . . . . . . . . . . . . . . . . . . . .'), 0.015873015873015872), (Document(metadata={'author': '', 'page_label': '2', 'producer': 'pdfTeX-1.40.25', 'creationdate': '2023-07-20T00:30:36+00:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'moddate': '2023-07-20T00:30:36+00:00', 'title': '', 'keywords': '', 'page': 1, 'source': '../data/pdf.pdf', 'creator': 'LaTeX with hyperref', 'total_pages': 77, 'subject': ''}, page_content='. . . . . . . 72 a.6 dataset contamination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75 a.7 model card . . . . . . . . . . . . . . . . . . . . . . . . . . . .'), 0.015625), (Document(metadata={'moddate': '2023-07-20T00:30:36+00:00', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'subject': '', 'page': 8, 'producer': 'pdfTeX-1.40.25', 'trapped': '/False', 'source': '../data/pdf.pdf', 'creator': 'LaTeX with hyperref', 'title': '', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'total_pages': 77, 'keywords': '', 'page_label': '9'}, page_content='different down- stream model performance, highlighting the importance of data checks even when using vendors to source annotations.'), 0.015625), (Document(metadata={'creationdate': '2023-07-20T00:30:36+00:00', 'title': '', 'keywords': '', 'author': '', 'page_label': '23', 'moddate': '2023-07-20T00:30:36+00:00', 'page': 22, 'creator': 'LaTeX with hyperref', 'subject': '', 'total_pages': 77, 'producer': 'pdfTeX-1.40.25', 'trapped': '/False', 'source': '../data/pdf.pdf', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5'}, page_content='and the techniques we use to mitigate safety risks. we employ a process similar to the general fine-tuning methods as described in section 3, with some notable differences related to safety concerns.'), 0.015625), (Document(metadata={'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': '', 'trapped': '/False', 'subject': '', 'total_pages': 77, 'source': '../data/pdf.pdf', 'producer': 'pdfTeX-1.40.25', 'page': 74, 'creationdate': '2023-07-20T00:30:36+00:00', 'creator': 'LaTeX with hyperref', 'author': '', 'keywords': '', 'page_label': '75', 'moddate': '2023-07-20T00:30:36+00:00'}, page_content='web, but not the question and answer continuation. as such, highly contaminated samples from these datasets are unlikely to gain an unfair advantage. the methodology in chowdhery et al. (2022)'), 0.015384615384615385), (Document(metadata={'creationdate': '2023-07-20T00:30:36+00:00', 'page': 4, 'subject': '', 'keywords': '', 'total_pages': 77, 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'source': '../data/pdf.pdf', 'title': '', 'author': '', 'page_label': '5', 'moddate': '2023-07-20T00:30:36+00:00', 'producer': 'pdfTeX-1.40.25'}, page_content='data from metas products or services. we made an effort to remove data from certain sites known to contain a high volume of personal information about private individuals. we trained on 2 trillion'), 0.015384615384615385), (Document(metadata={'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'total_pages': 77, 'subject': '', 'creationdate': '2023-07-20T00:30:36+00:00', 'moddate': '2023-07-20T00:30:36+00:00', 'title': '', 'keywords': '', 'page': 8, 'page_label': '9', 'source': '../data/pdf.pdf', 'author': '', 'trapped': '/False'}, page_content='different down- stream model performance, highlighting the importance of data checks even when using vendors to source annotations.'), 0.015384615384615385), (Document(metadata={'keywords': '', 'producer': 'pdfTeX-1.40.25', 'creationdate': '2023-07-20T00:30:36+00:00', 'total_pages': 77, 'creator': 'LaTeX with hyperref', 'moddate': '2023-07-20T00:30:36+00:00', 'page': 8, 'title': '', 'page_label': '9', 'subject': '', 'trapped': '/False', 'source': '../data/pdf.pdf', 'author': '', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5'}, page_content='different down- stream model performance, highlighting the importance of data checks even when using vendors to source annotations.'), 0.015151515151515152), (Document(metadata={'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'keywords': '', 'page': 35, 'title': '', 'trapped': '/False', 'producer': 'pdfTeX-1.40.25', 'total_pages': 77, 'author': '', 'creationdate': '2023-07-20T00:30:36+00:00', 'subject': '', 'source': '../data/pdf.pdf', 'page_label': '36', 'moddate': '2023-07-20T00:30:36+00:00', 'creator': 'LaTeX with hyperref'}, page_content='underscore various hazards likebias,toxicity,privatedataleakage,andthepotentialformalicioususes. solaimanetal.(2023)categorizes these impacts into two groups those that can be assessed within the'), 0.015151515151515152), (Document(metadata={'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'page': 35, 'trapped': '/False', 'title': '', 'creator': 'LaTeX with hyperref', 'author': '', 'page_label': '36', 'producer': 'pdfTeX-1.40.25', 'keywords': '', 'subject': '', 'total_pages': 77, 'moddate': '2023-07-20T00:30:36+00:00', 'creationdate': '2023-07-20T00:30:36+00:00', 'source': '../data/pdf.pdf'}, page_content='underscore various hazards likebias,toxicity,privatedataleakage,andthepotentialformalicioususes. solaimanetal.(2023)categorizes these impacts into two groups those that can be assessed within the'), 0.015151515151515152), (Document(metadata={'title': '', 'subject': '', 'creationdate': '2023-07-20T00:30:36+00:00', 'trapped': '/False', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'page': 74, 'total_pages': 77, 'keywords': '', 'page_label': '75', 'source': '../data/pdf.pdf', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'author': ''}, page_content='the training data. this was a deliberately conservative approach in order to produce a clean subset of the data with high precision, and is used in open-sourced evaluation libraries (e.g. gao et al.'), 0.014925373134328358), (Document(metadata={'author': '', 'moddate': '2023-07-20T00:30:36+00:00', 'page_label': '20', 'creator': 'LaTeX with hyperref', 'page': 19, 'source': '../data/pdf.pdf', 'total_pages': 77, 'creationdate': '2023-07-20T00:30:36+00:00', 'subject': '', 'trapped': '/False', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': '', 'keywords': ''}, page_content='share a model card in the appendix, in table 52. 4.1 safety in pretraining it is important to understand what is in the pretraining data both to increase transparency and to shed light on root causes'), 0.014925373134328358), (Document(metadata={'total_pages': 77, 'subject': '', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'page': 75, 'title': '', 'page_label': '76', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'source': '../data/pdf.pdf', 'producer': 'pdfTeX-1.40.25', 'moddate': '2023-07-20T00:30:36+00:00', 'trapped': '/False', 'keywords': ''}, page_content='contamination, and we omit results from these datasets for conciseness. 76'), 0.014925373134328358)]\\n\\nQuestion: How to prevent data contamination?\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:RunnableSequence > llm:ChatOpenAI] [1.36s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"To prevent data contamination, it is important to understand what is in the pretraining data, remove data from certain sites known to contain a high volume of personal information about private individuals, and use a conservative approach to produce a clean subset of the data with high precision. It is also essential to conduct data checks even when using vendors to source annotations and employ processes to mitigate safety risks related to the data.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To prevent data contamination, it is important to understand what is in the pretraining data, remove data from certain sites known to contain a high volume of personal information about private individuals, and use a conservative approach to produce a clean subset of the data with high precision. It is also essential to conduct data checks even when using vendors to source annotations and employ processes to mitigate safety risks related to the data.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 80,\n",
      "                \"prompt_tokens\": 5434,\n",
      "                \"total_tokens\": 5514,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"id\": \"chatcmpl-BiiOaqALnLuPz1HmiXcCun0TfTSIH\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--5b9be389-0d85-4cf5-b2b5-2499391d1d49-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 5434,\n",
      "              \"output_tokens\": 80,\n",
      "              \"total_tokens\": 5514,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 80,\n",
      "      \"prompt_tokens\": 5434,\n",
      "      \"total_tokens\": 5514,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"id\": \"chatcmpl-BiiOaqALnLuPz1HmiXcCun0TfTSIH\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"To prevent data contamination, it is important to understand what is in the pretraining data, remove data from certain sites known to contain a high volume of personal information about private individuals, and use a conservative approach to produce a clean subset of the data with high precision. It is also essential to conduct data checks even when using vendors to source annotations and employ processes to mitigate safety risks related to the data.\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence] [3.18s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"To prevent data contamination, it is important to understand what is in the pretraining data, remove data from certain sites known to contain a high volume of personal information about private individuals, and use a conservative approach to produce a clean subset of the data with high precision. It is also essential to conduct data checks even when using vendors to source annotations and employ processes to mitigate safety risks related to the data.\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T14:13:11.014935Z",
     "start_time": "2025-06-15T14:13:10.968716Z"
    }
   },
   "cell_type": "code",
   "source": "response1",
   "id": "a76bb18269f9d194",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To prevent data contamination, it is important to understand what is in the pretraining data, remove data from certain sites known to contain a high volume of personal information about private individuals, and use a conservative approach to produce a clean subset of the data with high precision. It is also essential to conduct data checks even when using vendors to source annotations and employ processes to mitigate safety risks related to the data.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "589afea8caeb59e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
